# Project Kickoff Guide: Core Banking System on Netlify

## 1. Goal

Build a core banking system using microservices deployed on Netlify. The system must be fully compliant with relevant regulations.

## 2. Core Principles

1.  **Microservices:** Decompose functionality into independent services.
2.  **Serverless First:** Leverage Netlify Functions for backend logic and Supabase for managed database/backend services.
3.  **Local First Development:** Prioritize local development and testing using `netlify dev`. Debugging deployed functions should be the exception, not the rule.
4.  **Clear Separation:** Maintain separation between frontend (UI), backend functions (API logic), database (Supabase), and authentication (Auth0).
5.  **Infrastructure as Code:** Define build settings, redirects, and function directories in `netlify.toml`. Manage database schema changes with Supabase migrations.
6.  **Compliance First:** Ensure all design choices meet regulatory requirements (e.g., GDPR, PCI DSS, Open Banking).
7.  **Secure by Default:** Implement proper token validation in *every* function that requires authentication. Use environment variables securely. Follow least privilege principles.
8.  **Leverage Off-the-Shelf Components:** Utilize existing managed solutions for common concerns like IAM (Auth0), database (Supabase), asynchronous tasks (Inngest), and sensitive data vaulting (VGS) where possible to reduce operational burden.
9.  **Open Banking Standards:** Adhere to the principles and specifications of relevant Open Banking Standards (e.g., UK Open Banking, FAPI) for API design, security profiles, and data models where applicable.
10. **Automation:** Leverage Git for version control and Netlify's Git integration for automated deployments and CI/CD.

## 3. Architecture Outline

This project adopts a serverless microservices architecture hosted on Netlify.

*   **Frontend:** (To be determined - potentially a static site generated by a framework like React/Vue/Svelte) served by Netlify CDN.
*   **Backend Logic:** Implemented as individual Node.js microservices deployed as Netlify Functions.
*   **Database:** PostgreSQL managed by Supabase.
*   **Authentication & Authorization:** Handled by Auth0 (external Identity Provider).
*   **Asynchronous Tasks & Workflows:** Orchestrated using Inngest.
*   **Sensitive Data Vaulting:** Highly sensitive data (e.g., PCI scope) potentially tokenized via Very Good Security (VGS).
*   **API Gateway:** Netlify's built-in capabilities (redirects, functions) serve as the primary API gateway.

Inter-service communication will primarily be asynchronous via Inngest, with synchronous REST calls used sparingly for essential queries.

## 4. Key Technology Choices & Rationale

*   **Hosting & Serverless Functions: Netlify**
    *   **Rationale:** Provides integrated hosting, serverless functions, CI/CD, CDN, environment management, and developer tooling (`netlify dev`) aligned with a serverless, Git-driven workflow. Simplifies deployment and infrastructure management.
*   **Identity & Access Management (IAM): Auth0**
    *   **Rationale:** Mature, dedicated IAM SaaS platform. Offers comprehensive features (MFA, RBAC, audit logs, user management), strong security posture, compliance certifications (SOC 2, ISO 27001), and support for standards like FAPI required for banking. Reduces the burden of building and maintaining a complex, secure identity system. Netlify Identity is deprecated.
*   **Database: Supabase (PostgreSQL)**
    *   **Rationale:** Provides a managed PostgreSQL database, suitable for transactional integrity. Includes helpful backend-as-a-service features (e.g., generated APIs, authentication hooks - though we primarily use Auth0). Offers Row Level Security (RLS), connection pooling considerations, and is designed for serverless function integration. Reduces DB operational overhead.
*   **Asynchronous Communication & Workflows: Inngest**
    *   **Rationale:** Combines event streaming, queuing, scheduling, and durable workflow execution (steps, retries, state management) specifically tailored for serverless environments like Netlify. Offers a strong Developer Experience (DX), observability, and local development support, simplifying the implementation of resilient, complex, multi-step processes compared to traditional queues. SOC 2 compliant (detailed review pending).
*   **Sensitive Data Vaulting: Very Good Security (VGS) (Potential)**
    *   **Rationale:** If handling highly sensitive data like full PANs, VGS can tokenize/vault this data *before* it reaches our systems (including Supabase). This significantly reduces the scope and complexity of achieving compliance standards like PCI DSS by keeping the raw sensitive data out of our direct control.

## 5. Prerequisites

*   **Node.js & npm/yarn:** Latest LTS version recommended.
*   **Git:** For version control and Netlify deployment.
*   **Accounts:**
    *   [Netlify](https://app.netlify.com/)
    *   [Supabase](https://app.supabase.io/)
    *   [Auth0](https://auth0.com/)
    *   (Potentially Inngest, VGS later)
*   **IDE:** VS Code / Cursor recommended.
*   **Netlify CLI:** To be installed locally via npm.
*   **(Optional) REST Client:** Postman, Insomnia, or VS Code REST Client extension for API testing.

## 6. Initial Project Setup

1.  **Create Project Directory:**
    ```bash
    # Choose a suitable project name, e.g., bank_ai_core
    mkdir bank_ai_core
    cd bank_ai_core
    ```
2.  **Initialize npm & Git:**
    ```bash
    npm init -y
    git init
    ```
3.  **Install Core Dependencies:**
    *   **Runtime:** `@supabase/supabase-js` (Supabase client), `jsonwebtoken` (JWT verification), `jwks-rsa` (fetch Auth0 signing keys). Add `inngest` when integrating asynchronous tasks.
    *   **Development:** `netlify-cli` (for local development and deployment).
    ```bash
    # Runtime Dependencies
    npm install @supabase/supabase-js jsonwebtoken jwks-rsa 

    # Development Dependency
    npm install -D netlify-cli 
    ```
4.  **Create `.gitignore`:** Add `node_modules/`, `.env*`, `*.log`, sensitive configuration, etc.
    ```gitignore
    node_modules/
    .env*
    *.log
    ```
5.  **Establish Basic Directory Structure:**
    ```
    /bank_ai_core
    ├── functions/         # Netlify functions root directory
    │   └── .gitkeep       # Placeholder to keep the directory in Git
    ├── public/            # Static frontend assets (if any)
    │   └── index.html     # Simple placeholder page
    ├── .gitignore
    ├── netlify.toml       # Netlify configuration file
    └── package.json
    ```
    *   Create these directories and the placeholder `.gitkeep` file.
6.  **Create `public/index.html` (Placeholder):** A minimal HTML file for Netlify Dev to serve.
    ```html
    <!DOCTYPE html>
    <html>
    <head><title>Core Banking API</title></head>
    <body><h1>Core Banking API - Local Dev Server</h1></body>
    </html>
    ```
7.  **Create `netlify.toml`:** Configure Netlify build, deployment, and development settings.
    ```toml
    # netlify.toml

    [build]
      # Command to build frontend assets (if any). For now, none needed.
      command = "echo 'No build command needed for now'" 
      # Directory containing deployable static files (e.g., index.html).
      publish = "public/"    
      # Directory where Netlify Functions live.
      functions = "functions/" 

    # Configuration for the local development server (netlify dev)
    [dev]
      # Optional: Specify port for netlify dev (default is often 8888)
      # port = 8888 
      # Optional: Specify command to run in parallel (e.g., frontend dev server)
      # command = "npm run start:frontend" # Example if you have a frontend process
      # targetPort = 3000 # Port your frontend framework runs on

    # Example redirect to proxy API calls to Netlify functions
    # This makes your local functions accessible via /api/* paths
    [[redirects]]
      from = "/api/*"
      # Proxies request to the function matching the path segment after /api/
      # e.g., /api/transaction-service -> /.netlify/functions/transaction-service
      to = "/.netlify/functions/:splat" 
      status = 200 # OK status for proxy

    # More specific redirects can be added later if needed, e.g.:
    # [[redirects]]
    #   from = "/api/transactions/*"
    #   to = "/.netlify/functions/transaction-service" # Route all to one function
    #   status = 200
    #   force = true # Ensures this redirect takes precedence
    ```

## 7. Cloud Service Setup (Initial Configuration)

Get the necessary credentials and configure the services. Store secrets securely.

1.  **Auth0:**
    *   **Create API (Resource Server):**
        *   Go to Auth0 Dashboard -> Applications -> APIs -> Create API.
        *   **Name:** `Core Banking API` (or similar).
        *   **Identifier (Audience):** `https://api.core-banking.example.com` (use a unique, persistent URI-like value; this is your `AUTH0_AUDIENCE`). It doesn't have to be a real URL.
        *   **Signing Algorithm:** `RS256` (Asymmetric, recommended).
        *   **Record:** The **Identifier (Audience)**.
    *   **Create M2M Application (for Backend Testing/Seed Scripts):**
        *   Go to Applications -> Applications -> Create Application.
        *   **Name:** `Core Banking API Test Client`.
        *   **Type:** Select **Machine to Machine Applications**.
        *   Click Create.
        *   On the next screen, select the API you just created (`Core Banking API`) from the dropdown and authorize it. You can select specific scopes later if defined.
        *   Ensure the `client_credentials` grant type is enabled (Settings tab).
        *   **Record:** The **Domain**, **Client ID**, and **Client Secret** from the Settings tab. **Treat the Client Secret like a password.**
    *   **(Optional but Recommended) Define API Permissions (Scopes):**
        *   Go back to Applications -> APIs -> Select your `Core Banking API`.
        *   Go to the "Permissions" tab.
        *   Define granular scopes (e.g., `create:transfer`, `read:accounts`, `manage:customers`).
        *   Go back to the M2M Application -> "APIs" tab -> Expand the authorized `Core Banking API`.
        *   Grant the necessary scopes to your M2M client for testing purposes.

2.  **Supabase:**
    *   **Create Project:**
        *   Go to [Supabase Dashboard](https://app.supabase.io/) -> New Project.
        *   Choose Name, Database Password (save securely!), Region.
    *   **Get API Credentials:**
        *   Once the project is running, go to Project Settings (Gear icon) -> API.
        *   Find the **Project URL**.
        *   Find the **API Keys**. You will primarily need the `service_role` **Secret** key for backend functions that need to bypass Row Level Security (use with extreme care).
        *   **Record:** The **Project URL** and the `service_role` **Secret** Key. **Treat the service_role key as highly sensitive.**
    *   **(Recommended) Define Initial Schema:**
        *   Use the Supabase UI (Table Editor, SQL Editor) or Supabase Migrations (via Supabase CLI, recommended for team collaboration) to define initial tables (e.g., `customers`, `accounts`, `ledger_entries`). See Section 10 for initial designs. Consider using UUIDs for primary keys.
        *   Enable Row Level Security (RLS) on tables containing sensitive data (Authentication -> Policies).

3.  **Netlify:**
    *   **Create Site from Git:**
        *   Push your initial project structure (including `netlify.toml`) to a Git repository (GitHub, GitLab, Bitbucket).
        *   Go to Netlify Dashboard -> Add new site -> Import an existing project.
        *   Connect to your Git provider.
        *   Select the repository.
        *   Configure build settings (usually auto-detected from `netlify.toml`). Ensure the base directory, build command, and publish directory are correct.
        *   Deploy the site.
    *   **Configure Environment Variables (Critical):**
        *   Go to the newly created Site settings -> Build & deploy -> Environment -> Environment variables.
        *   Click "Add a variable" -> "Create a single variable".
        *   Add the following variables using the values you recorded from Auth0 and Supabase:
            *   `SUPABASE_URL` (Your Supabase Project URL)
            *   `SUPABASE_SERVICE_ROLE_KEY` (Your Supabase `service_role` secret key)
            *   `AUTH0_DOMAIN` (Your Auth0 Domain, e.g., `your-tenant.us.auth0.com`)
            *   `AUTH0_AUDIENCE` (The API Identifier/Audience you created in Auth0)
            *   (Optionally: Add M2M Client ID/Secret if needed directly server-side, though often not required *within* functions if the token is generated externally for testing).
        *   **Scope:** Ensure these are available to Functions and during Builds/Deploys as needed. The default "All scopes" is usually fine initially.

## 8. Local Development Workflow

This setup allows for efficient local development and testing of Netlify Functions before deploying.

1.  **Link Local Project to Netlify Site:**
    *   Run this command in the project root (`bank_ai_core`):
    ```bash
    npx netlify link
    ```
    *   Follow the prompts to connect to your Netlify account and select the Netlify site you created in Step 7.3. This links your local environment to the site's settings, including environment variables.

2.  **Start Netlify Dev:**
    *   Run this command in the project root:
    ```bash
    npx netlify dev
    ```
    *   This command is central to the local workflow:
        *   Starts a local web server (e.g., `http://localhost:8888` or another available port) serving content from your `publish` directory (`public/`).
        *   Automatically detects and serves functions from your `functions` directory.
        *   Applies redirects defined in `netlify.toml` (e.g., `/api/*` proxy).
        *   **Crucially, it injects the environment variables** you configured in the Netlify UI (Step 7.3) into your local function execution environment. Your local functions can now access `process.env.SUPABASE_URL`, `process.env.AUTH0_DOMAIN`, etc.
        *   Provides live reload for functions – changes you make to function code are typically reflected without restarting `netlify dev`.

3.  **(Optional) Local Environment Variables (`.env` file):**
    *   For variables you don't want to store in the Netlify UI (e.g., local-only overrides, sensitive dev keys), you can create a `.env` file in the project root.
    *   **Ensure `.env` is listed in your `.gitignore` file!**
    *   `netlify dev` will load variables from this file, and they will *override* variables with the same name fetched from the Netlify UI.
    ```.env
    # Example .env file - DO NOT COMMIT SENSITIVE VALUES
    # SUPABASE_URL=local_override_or_different_dev_supabase_url
    # SUPABASE_SERVICE_ROLE_KEY=local_override_dev_service_key
    # AUTH0_DOMAIN=your_auth0_domain
    # AUTH0_AUDIENCE=your_auth0_audience
    # M2M_TEST_CLIENT_ID=local_m2m_id # For local testing scripts
    # M2M_TEST_CLIENT_SECRET=local_m2m_secret # For local testing scripts
    ```

## 9. Example: Creating & Testing a Secure Function

This example demonstrates creating a basic Netlify Function (`transaction-service`) that requires a valid Auth0 JWT for access.

1.  **Create Function File:**
    *   Netlify Functions can be organized in subdirectories. The directory name often corresponds to the function's endpoint name.
    *   Create: `functions/transaction-service/transaction-service.js`
    ```javascript
    // functions/transaction-service/transaction-service.js
    const { createClient } = require('@supabase/supabase-js');
    const jwt = require('jsonwebtoken');
    const jwksClient = require('jwks-rsa');

    // --- Environment Variable Configuration --- 
    const supabaseUrl = process.env.SUPABASE_URL;
    const supabaseServiceRoleKey = process.env.SUPABASE_SERVICE_ROLE_KEY;
    const auth0Domain = process.env.AUTH0_DOMAIN;
    const auth0Audience = process.env.AUTH0_AUDIENCE;

    // --- Initial Checks & Service Clients --- 
    // Basic check for required env vars (can be done outside handler for efficiency)
    if (!supabaseUrl || !supabaseServiceRoleKey || !auth0Domain || !auth0Audience) {
        console.error('FATAL: Missing required environment variables at startup.');
        // Optionally throw an error to prevent the function from being served if critical config is missing
        // throw new Error("Missing required environment variables"); 
    }

    // Initialize Supabase client (using service role key for backend operations)
    // WARNING: Service role key bypasses RLS. Use cautiously.
    const supabase = createClient(supabaseUrl, supabaseServiceRoleKey);

    // Initialize JWKS client to fetch Auth0 public keys for token verification
    const jwksRsaClient = jwksClient({
        jwksUri: `https://${auth0Domain}/.well-known/jwks.json`,
        cache: true, // Cache signing keys for performance
        rateLimit: true // Prevent abuse
    });

    // --- Auth Token Verification Logic --- 
    // Function to retrieve the Auth0 signing key based on the JWT header
    function getSigningKey(header, callback) {
        jwksRsaClient.getSigningKey(header.kid, (err, key) => {
            if (err) {
                console.error('Error getting signing key:', err);
                return callback(err);
            }
            const signingKey = key.publicKey || key.rsaPublicKey;
            callback(null, signingKey);
        });
    }

    // Async function to verify the Authorization header token
    async function verifyToken(authHeader) {
        if (!authHeader || !authHeader.startsWith('Bearer ')) {
            // Standard practice to return 401 for missing/malformed auth
            throw { statusCode: 401, message: 'Missing or invalid Authorization header. Expected: Bearer <token>' };
        }
        // Extract token part after "Bearer "
        const token = authHeader.substring(7);

        return new Promise((resolve, reject) => {
            jwt.verify(token, getSigningKey, {
                audience: auth0Audience, // Verify token is intended for our API
                issuer: `https://${auth0Domain}/`, // Verify token was issued by our Auth0 domain
                algorithms: ['RS256'] // Ensure the expected algorithm is used
            }, (err, decoded) => {
                if (err) {
                    console.error('JWT verification error:', err);
                    // Map JWT errors (like expiration, invalid signature) to 401
                    return reject({ statusCode: 401, message: `Token verification failed: ${err.message}` });
                }
                // Token is valid, resolve with the decoded payload
                resolve(decoded); // Contains claims like sub, scope, etc.
            });
        });
    }

    // --- Main Netlify Function Handler --- 
    exports.handler = async (event, context) => {
        // Re-check critical env vars within the handler context as a safeguard
        if (!supabaseUrl || !supabaseServiceRoleKey || !auth0Domain || !auth0Audience) {
           console.error('Handler Error: Missing required environment variables.');
           return { statusCode: 500, body: JSON.stringify({ message: 'Server configuration error' }) };
        }

        // --- Request Routing & Processing --- 
        // Determine the specific API path being requested within this function
        // event.path might be /.netlify/functions/transaction-service/some/route 
        // or just /some/route depending on Netlify proxy behavior.
        // This regex removes the function prefix to get the sub-path.
        const subPath = event.path.replace(/^\/?(\.netlify\/functions\/)?[^\/]+/, '') || '/'; 
        const method = event.httpMethod;

        console.log(`Request received: ${method} ${event.path} (SubPath: ${subPath})`);

        try {
            // --- Authentication & Authorization --- 
            // Secure the endpoint by verifying the token on every request
            const verifiedToken = await verifyToken(event.headers.authorization);
            // Log subject (user ID or client ID) and grant type for auditing/debugging
            console.log(`Token verified for sub: ${verifiedToken.sub}, grant_type: ${verifiedToken.gty}`);

            // Optional: Check for specific scopes/permissions within the token if needed
            // const requiredScope = 'create:transfer';
            // if (!verifiedToken.scope || !verifiedToken.scope.includes(requiredScope)) {
            //    throw { statusCode: 403, message: `Forbidden: Missing required scope (${requiredScope})` };
            // }

            // --- API Route Handling --- 
            // Simple routing based on HTTP method and the calculated sub-path
            if (method === 'POST' && subPath === '/internal-transfer') {
                console.log('Handling POST /internal-transfer');
                let body = {};
                try {
                    body = JSON.parse(event.body || '{}');
                } catch (parseError) {
                    return { statusCode: 400, body: JSON.stringify({ message: 'Invalid JSON request body' }) };
                }

                // TODO: Implement internal transfer logic using Supabase client
                // - Validate request body (fromAccountId, toAccountId, amount, currency)
                // - Check if `verifiedToken.sub` has authority to use `fromAccountId`
                // - Call Supabase RPC function `post_ledger_transaction` (see Section 10)
                console.log('Request Body:', body);
                console.log('Caller (sub):', verifiedToken.sub);

                // Placeholder success response
                 return {
                    statusCode: 200,
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ 
                        message: "Internal transfer request received (placeholder logic)", 
                        details: { 
                            requestBody: body,
                            callerSub: verifiedToken.sub 
                        }
                    })
                 };
            }
            // Add other routes for this service (e.g., GET /transactions/{id})
            else if (method === 'GET' && subPath === '/status') {
                return {
                    statusCode: 200,
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ message: "Transaction service is active", callerSub: verifiedToken.sub })
                 };
            }
            // Default: Route not found within this function
            else {
                 return { statusCode: 404, body: JSON.stringify({ message: 'Function route not found' }) };
            }

        } catch (error) {
            // --- Centralized Error Handling --- 
            console.error('Function Error:', error);
            // Return a structured error response
            // Use error.statusCode if available (e.g., from verifyToken), otherwise default to 500
            return {
                statusCode: error.statusCode || 500,
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ message: error.message || 'Internal Server Error' })
            };
        }
    };
    ```

2.  **Get M2M Test Token:**
    *   Use `curl` or a REST client to request an Access Token from Auth0 using the M2M application credentials you set up (Step 7.1).
    *   **Replace `{...}` placeholders with *your actual* Auth0 Domain, M2M Client ID, M2M Client Secret, and API Audience.**
    ```bash
    curl --request POST \
      --url "https://{your_auth0_domain}/oauth/token" \
      --header 'content-type: application/json' \
      --data '{
        "client_id": "{your_m2m_client_id}",
        "client_secret": "{your_m2m_client_secret}",
        "audience": "{your_api_audience}",
        "grant_type": "client_credentials"
      }'
    ```
    *   From the JSON response, copy the value of the `access_token`. This token represents your M2M client application.

3.  **Test Locally:**
    *   Ensure `netlify dev` is running in your terminal.
    *   Use `curl` (or your REST client) to send a request to the local function endpoint exposed by `netlify dev`, including the copied `access_token` in the `Authorization` header.

    *   **Example POST to `/internal-transfer`:**
        ```bash
        # Store the token in an environment variable (optional, convenient)
        export M2M_TOKEN="<PASTE_YOUR_COPIED_M2M_ACCESS_TOKEN_HERE>" 
        
        # Make the request
        curl --request POST \
          --url "http://localhost:8888/api/transaction-service/internal-transfer" \
          --header "Authorization: Bearer $M2M_TOKEN" \
          --header "Content-Type: application/json" \
          --data '{ "fromAccountId": "acc_uuid_1", "toAccountId": "acc_uuid_2", "amount": 150.75, "currency": "USD" }'
        ```
    *   **Example GET to `/status`:**
        ```bash
        curl --request GET \
          --url "http://localhost:8888/api/transaction-service/status" \
          --header "Authorization: Bearer $M2M_TOKEN"
        ```
    *   You should see the JSON response from your function in the terminal where you ran `curl`. You should also see `console.log` output in the terminal where `netlify dev` is running.
    *   Try sending the request *without* the `Authorization` header or with an invalid token to see the `401 Unauthorized` error response.

4.  **Debug (VS Code / Cursor):**
    *   Set breakpoints directly in your `transaction-service.js` file within the IDE.
    *   Run `netlify dev`.
    *   Trigger the function by sending a request using `curl` or your REST client.
    *   Execution should pause at your breakpoint, allowing you to inspect variables (`event`, `context`, `verifiedToken`, etc.) and step through the code.

## 10. Initial Microservice Designs

This section outlines the initial set of microservices and their responsibilities, based on the architectural plan. Data models refer to tables/functions within the **Supabase database**. API endpoints represent the routes exposed by the **Netlify Functions**.

**Initial Microservice Set:**

*   `customer-service`: Manages customer profiles and lifecycle.
*   `account-service`: Manages bank accounts (creation, status, details).
*   `ledger-service`: Provides the immutable, double-entry ledger (implemented primarily via Supabase DB functions).
*   `transaction-service`: Handles transaction requests (e.g., transfers) and orchestrates ledger posting.
*   `notification-service`: (Future) Handles sending notifications (email, SMS).
*   `consent-management-service`: (Future) Manages user consents for data sharing/payments.

--- 

### account-service

**1. Core Responsibilities:**

*   Create new bank accounts (Checking, Savings) associated with a verified `customer_id`.
*   Retrieve detailed information for a specific account, including calculated balance (using `ledger-service` capabilities).
*   List all accounts belonging to a specific customer.
*   Update account status (e.g., active, dormant, closed).
*   Generate unique, non-predictable account numbers.
*   Interface with the `ledger-service` (or underlying ledger tables/RPCs) to determine account balances.
*   Potentially trigger asynchronous background jobs (via Inngest) for tasks like statement generation.

**2. Potential API Endpoints (Exposed by `functions/account-service/account-service.js`):**

*   `POST /api/account-service/accounts` (Requires authenticated user context, likely `customer_id` from JWT or session)
*   `GET /api/account-service/accounts?customerId={customerId}` (Requires authz check: is requesting user the customer or authorized staff?)
*   `GET /api/account-service/accounts/{accountId}` (Requires authz check)
*   `PATCH /api/account-service/accounts/{accountId}` (Requires authz check for status updates, etc.)

**3. Data Model (`accounts` table in Supabase):**

```sql
-- Use ENUM types for controlled vocabularies
CREATE TYPE public.account_type_enum AS ENUM ('CHECKING', 'SAVINGS');
CREATE TYPE public.account_status_enum AS ENUM ('ACTIVE', 'DORMANT', 'PENDING_CLOSURE', 'CLOSED');

CREATE TABLE public.accounts (
    id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
    created_at timestamptz NOT NULL DEFAULT now(),
    -- Foreign key linking to the customer owning this account
    customer_id uuid NOT NULL REFERENCES public.customers(id), 
    account_number text NOT NULL UNIQUE, -- Needs robust generation logic
    account_type public.account_type_enum NOT NULL,
    status public.account_status_enum NOT NULL DEFAULT 'ACTIVE'::public.account_status_enum,
    currency character(3) NOT NULL DEFAULT 'USD'::bpchar, -- ISO 4217 currency code
    nickname text NULL, 
    -- Balance is not stored here; it's calculated dynamically from the ledger.
    CONSTRAINT fk_customer FOREIGN KEY (customer_id) REFERENCES public.customers(id)
);

-- Indexes for efficient lookups
CREATE INDEX idx_accounts_customer_id ON public.accounts(customer_id);
CREATE INDEX idx_accounts_account_number ON public.accounts(account_number);

-- Enable Row Level Security (RLS) for this table!
ALTER TABLE public.accounts ENABLE ROW LEVEL SECURITY;

-- Example RLS Policy: Allow customer to see their own accounts
-- CREATE POLICY select_own_accounts ON public.accounts
--   FOR SELECT USING (customer_id = (SELECT customer_id FROM public.users WHERE auth0_user_id = auth.uid())); 
--   -- Note: Assumes a users/customers table linked to auth.uid() from Auth0
```

**4. Dependencies:**

*   `customer-service` (Implicit via `customer_id` FK, potential direct calls)
*   `ledger-service` (Specifically, the `calculate_balance` RPC function)
*   Auth0 (for JWT validation and getting user context)
*   Inngest (optional, for background tasks like statement generation)

--- 

### ledger-service

**Note:** This service's core logic resides primarily within **Supabase database functions (RPCs)** to ensure atomicity and data integrity for financial transactions.

**1. Core Responsibilities:**

*   Atomically record balanced, double-entry financial transactions (debit/credit pairs must sum to zero per logical transaction).
*   Ensure immutability of posted ledger entries (no updates/deletes, only reversals via new entries).
*   Provide a mechanism to query entries for accurate balance calculation.

**2. Data Model (`ledger_entries` table in Supabase):**

```sql
-- Enum Type for Debit/Credit
CREATE TYPE public.ledger_entry_type_enum AS ENUM ('DEBIT', 'CREDIT');

-- Main table for immutable ledger entries
CREATE TABLE public.ledger_entries (
    id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY, -- Sequential ID for ordering
    created_at timestamptz NOT NULL DEFAULT now(), -- Timestamp of entry creation
    -- Groups entries belonging to the same logical financial transaction (e.g., a transfer)
    transaction_id uuid NOT NULL, 
    -- Account affected by this specific entry (debit or credit)
    account_id uuid NOT NULL REFERENCES public.accounts(id),
    entry_type public.ledger_entry_type_enum NOT NULL,
    -- Amount for this entry (always positive). Use NUMERIC for precision.
    amount numeric(19, 4) NOT NULL CHECK (amount > 0), 
    currency character(3) NOT NULL, -- ISO 4217 currency code
    description text NULL, -- Optional description for the entry
    CONSTRAINT fk_account FOREIGN KEY (account_id) REFERENCES public.accounts(id)
);

-- Indexes for common queries (balance calculation, transaction lookup)
CREATE INDEX idx_ledger_entries_account_id_created_at ON public.ledger_entries(account_id, created_at DESC);
CREATE INDEX idx_ledger_entries_transaction_id ON public.ledger_entries(transaction_id);
CREATE INDEX idx_ledger_entries_created_at ON public.ledger_entries(created_at DESC);

-- RLS should also be considered here, though access might be restricted to backend roles/functions.
ALTER TABLE public.ledger_entries ENABLE ROW LEVEL SECURITY;
```

**3. Interaction Pattern: Supabase Database Functions (RPC)**

*   **Posting Entries (Example `post_ledger_transaction`):**
    *   A `plpgsql` function created directly in Supabase.
    *   **Input:** Transaction details (e.g., `from_account_id`, `to_account_id`, `amount`, `currency`, `transaction_uuid`, `description`).
    *   **Logic:**
        1.  Starts a database transaction.
        2.  **(Optional but recommended) Performs validation:** Checks if `from_account_id` exists and has sufficient funds (by calling `calculate_balance` within the transaction or using locking).
        3.  Inserts the `DEBIT` entry for `from_account_id` into `ledger_entries`.
        4.  Inserts the `CREDIT` entry for `to_account_id` into `ledger_entries`.
        5.  Commits the transaction.
    *   **Called By:** `transaction-service` Netlify Function using the Supabase client's `rpc()` method.
    *   **Benefit:** Guarantees atomicity – both debit and credit entries succeed or fail together.
*   **Balance Calculation (Example `calculate_balance`):**
    *   A `plpgsql` function created directly in Supabase.
    *   **Input:** `p_account_id uuid`.
    *   **Logic:** Calculates `SUM(amount WHERE entry_type = 'CREDIT') - SUM(amount WHERE entry_type = 'DEBIT')` for the given `account_id` from `ledger_entries`.
    *   **Returns:** Calculated balance `numeric(19, 4)`.
    *   **Called By:** `account-service` (or other services needing balances) using `rpc()`.

**4. Dependencies:**

*   `accounts` table (Foreign Key constraints)
*   Called by `transaction-service` (for posting) and `account-service` (for balance checks).

--- 

### transaction-service

**1. Core Responsibilities (Initial Focus):**

*   Receive and validate requests for internal account-to-account transfers.
*   Perform authorization checks (e.g., does the authenticated user own the source account?).
*   Generate a unique `transaction_id` (UUID) for the logical transaction.
*   Orchestrate the transaction by calling the `post_ledger_transaction` Supabase RPC function.
*   Return a success or failure response based on the RPC call result.
*   (Future) Handle other transaction types (external transfers, payments).
*   (Future) Potentially publish events via Inngest upon success/failure.

**2. Potential API Endpoint (Exposed by `functions/transaction-service/transaction-service.js`):**

*   `POST /api/transaction-service/transfers/internal`
    *   **Action:** Initiate an internal transfer between two accounts within the bank.
    *   **AuthZ:** Requires a valid Auth0 JWT. The function must verify that the subject (`sub`) claim in the JWT corresponds to a customer who owns the `fromAccountId`.
    *   **Request Body:** `{ "fromAccountId": "uuid", "toAccountId": "uuid", "amount": number, "currency": "USD"|"EUR", "description": "string?" }`
    *   **Response (Success - 200 OK):** `{ "transactionId": "uuid", "status": "COMPLETED" }` (Indicates the ledger RPC was called successfully)
    *   **Response (Errors):**
        *   `400 Bad Request`: Invalid input (missing fields, bad format).
        *   `401 Unauthorized`: Missing or invalid JWT.
        *   `403 Forbidden`: Authenticated user does not own `fromAccountId`.
        *   `422 Unprocessable Entity`: Business rule violation reported by the ledger RPC (e.g., insufficient funds, invalid account). Body may contain details from the DB error.
        *   `500 Internal Server Error`: Unexpected function error.

**3. Data Model Considerations:**

*   Relies entirely on the `ledger_entries` table being populated correctly by the `post_ledger_transaction` RPC.
*   Does not typically need its own persistent `transactions` table for simple internal transfers, as the state is captured in the ledger. A table might be needed for more complex, multi-stage transactions later.
*   The `transaction_id` (UUID) is generated within the Netlify Function code before calling the RPC.

**4. Dependencies:**

*   Auth0 (JWT validation, getting user context).
*   `ledger-service` (Specifically, the `post_ledger_transaction` RPC function).
*   Potentially `account-service` or direct DB access for ownership checks/validations.
*   UUID generation library (e.g., built-in `crypto.randomUUID()` in Node.js).
*   Inngest (Future, for event publishing).

--- 

### customer-service

**1. Core Responsibilities:**

*   Manage customer profiles (create, read, update).
*   Link customer profiles to their Auth0 user identity (`auth0_user_id`).
*   Handle customer lifecycle events (e.g., onboarding, status changes).
*   Potentially initiate KYC/AML verification processes (likely via integration with a third-party service, triggered by Inngest event).

**2. Potential API Endpoints (Exposed by `functions/customer-service/customer-service.js`):**

*   `POST /api/customer-service/customers` (Likely triggered post-signup/first login, takes Auth0 sub)
*   `GET /api/customer-service/customers/me` (Gets profile of the authenticated user)
*   `GET /api/customer-service/customers/{customerId}` (For authorized staff access)
*   `PATCH /api/customer-service/customers/me` (Update own profile)

**3. Data Model (`customers` table in Supabase):**

```sql
CREATE TYPE public.customer_status_enum AS ENUM ('PENDING_VERIFICATION', 'ACTIVE', 'SUSPENDED', 'CLOSED');

CREATE TABLE public.customers (
    id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
    created_at timestamptz NOT NULL DEFAULT now(),
    updated_at timestamptz NOT NULL DEFAULT now(),
    -- Link to the user in Auth0. Should be unique.
    auth0_user_id text NOT NULL UNIQUE, 
    email text NOT NULL UNIQUE, -- Often synced from Auth0 initially
    full_name text NULL,
    date_of_birth date NULL,
    address jsonb NULL, -- Store structured address info
    status public.customer_status_enum NOT NULL DEFAULT 'PENDING_VERIFICATION'::public.customer_status_enum,
    -- Add other KYC-related fields as necessary
    kyc_status text NULL -- e.g., 'NOT_STARTED', 'PENDING', 'VERIFIED', 'FAILED'
);

-- Index for quick lookup based on Auth0 ID
CREATE INDEX idx_customers_auth0_user_id ON public.customers(auth0_user_id);

-- Automatically update 'updated_at' timestamp
CREATE TRIGGER handle_updated_at BEFORE UPDATE ON public.customers 
  FOR EACH ROW EXECUTE PROCEDURE moddatetime (updated_at);

-- Enable Row Level Security!
ALTER TABLE public.customers ENABLE ROW LEVEL SECURITY;

-- Example RLS: Allow user to select/update their own customer record
-- CREATE POLICY select_own_customer ON public.customers
--   FOR SELECT USING (auth0_user_id = auth.uid());
-- CREATE POLICY update_own_customer ON public.customers
--   FOR UPDATE USING (auth0_user_id = auth.uid());
```

**4. Dependencies:**

*   Auth0 (JWT validation, getting `auth0_user_id`)
*   Inngest (Future, for triggering KYC workflows, etc.)

--- 

## 11. Key Architectural Considerations & Best Practices

Refer back to these points during development:

*   **Security:**
    *   **Authentication:** Validate Auth0 JWTs in *every* protected function using `jwks-rsa` and `jsonwebtoken` as shown in the example.
    *   **Authorization:** Implement fine-grained checks *after* authentication. Use Supabase RLS extensively. Check ownership within functions (e.g., does `token.sub` own `accountId`?). Use scopes in JWTs if needed.
    *   **Input Validation:** Rigorously validate all incoming data (path params, query params, request bodies) in each function to prevent injection attacks and ensure data integrity.
    *   **Secrets Management:** Use Netlify Environment Variables for all secrets. Never commit secrets to Git. Use the `.env` file only for local, non-sensitive overrides or local test secrets (and ensure it's in `.gitignore`). Implement secret rotation policies.
    *   **Least Privilege:** Grant minimal necessary permissions. Use Supabase `service_role` key only when absolutely necessary (e.g., backend processes); prefer user-context roles for RLS.
    *   **Data Encryption:** Ensure TLS is enforced (default with Netlify/Supabase/Auth0). Configure Supabase disk encryption. Evaluate need for application-level or column-level encryption for specific PII/sensitive fields.
    *   **VGS:** Strongly consider VGS if handling PCI-scope data (PANs) to reduce compliance burden.
    *   **Logging:** Log security-relevant events (login attempts, authorization failures, key actions) but *avoid logging sensitive data* (PII, secrets, full tokens).
    *   **Dependencies:** Regularly scan dependencies for vulnerabilities (`npm audit`, Snyk).
*   **Compliance:**
    *   **Regulations:** Be mindful of target regulations (GDPR, GLBA, PCI DSS, PSD2/SCA, local laws). Design with these in mind (data minimization, consent, audit trails, security controls).
    *   **Vendor Compliance:** Review compliance documentation for Netlify, Supabase, Auth0, Inngest (SOC 2, ISO 27001, PCI AoC, DPAs).
    *   **Data Residency:** Configure Supabase project region appropriately if data residency is required (e.g., GDPR).
    *   **Audit Trails:** Ensure sufficient logging across functions, Supabase (using `audit` schema or triggers), and Auth0 to meet audit requirements.
    *   **Consent Management:** Design and implement mechanisms for capturing, storing, and enforcing user consent (especially for Open Banking/GDPR).
*   **Inter-service Communication (Inngest):**
    *   Prefer asynchronous communication via Inngest for commands, events, and background tasks to improve resilience and decoupling.
    *   Use direct synchronous function calls (e.g., via `fetch`) sparingly, only for essential queries where immediate data is needed.
    *   Design events and function handlers to be idempotent (safe to retry).
    *   Leverage Inngest features for retries, delays, scheduling, and complex workflows.
*   **State Management:**
    *   Functions are stateless. All persistent business state resides in Supabase.
    *   Use Supabase ACID transactions (especially via RPC functions) for atomic updates.
    *   Manage multi-step workflow state via Supabase tables updated by Inngest-triggered functions, or leverage Inngest's state management capabilities.
    *   Design for eventual consistency in distributed workflows.
*   **Testing:**
    *   **Unit Tests:** Mock dependencies (Supabase client, Auth0 verification, Inngest client) to test function logic in isolation (Jest, Mocha).
    *   **Integration Tests:** Test functions against local Supabase (via Supabase CLI `start`/`stop`) and potentially mock Auth0/Inngest endpoints or use test accounts.
    *   **Contract Tests:** Define and verify contracts between functions and consumers (API clients, other functions, Inngest events).
    *   **E2E Tests:** Test critical flows against deployed environments (Netlify Deploy Previews, Staging).
    *   **Security Tests:** Integrate SAST, DAST, dependency scanning into CI/CD.
*   **Deployment (CI/CD):**
    *   Use Netlify's Git integration for automated builds and deploys.
    *   Set up distinct environments (Deploy Previews, Staging, Production) using Netlify contexts and scoped environment variables.
    *   Integrate automated testing (unit, integration) into the build pipeline.
    *   Manage Supabase schema changes using migrations (Supabase CLI) applied during the deployment process.
    *   Use manual approvals for production deployments.
    *   Leverage Netlify's instant rollbacks.

## 12. Initial Next Steps for the Team

1.  **Environment Setup:** Each team member follows Sections 5, 6, 7, and 8 to set up their local development environment, link it to the Netlify site, and confirm `netlify dev` runs correctly, injecting environment variables.
2.  **Understand the Example:** Work through Section 9, creating the example `transaction-service` function locally, obtaining an M2M token, and successfully calling/debugging the function.
3.  **Supabase Schema:** Review the initial schema designs in Section 10. Set up Supabase migrations using the Supabase CLI and apply the initial schema to the development Supabase instance.
4.  **Implement `customer-service`:** Develop the basic CRUD operations for the `customer-service` function, including linking to Auth0 `sub` upon creation. Implement RLS policies in Supabase for customer data.
5.  **Implement `account-service`:** Develop the `account-service` function, including CRUD operations and calling the `calculate_balance` Supabase RPC (which needs to be created first based on the ledger design).
6.  **Implement `ledger-service` RPCs:** Create the core `post_ledger_transaction` and `calculate_balance` functions directly within Supabase using `plpgsql`.
7.  **Refine `transaction-service`:** Update the example `transaction-service` to perform actual validation (account ownership check) and call the `post_ledger_transaction` RPC.
8.  **CI/CD Setup:** Begin establishing the basic CI/CD pipeline in Netlify, integrating linting and initial unit tests.
9.  **Compliance Review:** Start a deeper dive into the specific compliance requirements (e.g., FAPI for Auth0, detailed logging needs) based on target jurisdictions/products.

## 13. Document Maintenance

This document (`PROJECT_KICKOFF_GUIDE.md`) now serves as the primary architectural and setup guide.
